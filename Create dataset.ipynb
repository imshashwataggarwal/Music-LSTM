{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa \n",
    "import h5py \n",
    "import numpy as np\n",
    "\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'Music Data/nsynth-valid/audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Audio wav Files Processed\n",
      "100 Audio wav Files Processed\n",
      "200 Audio wav Files Processed\n",
      "300 Audio wav Files Processed\n",
      "400 Audio wav Files Processed\n",
      "500 Audio wav Files Processed\n",
      "600 Audio wav Files Processed\n",
      "700 Audio wav Files Processed\n",
      "800 Audio wav Files Processed\n",
      "900 Audio wav Files Processed\n",
      "1000 Audio wav Files Processed\n",
      "1100 Audio wav Files Processed\n",
      "1200 Audio wav Files Processed\n",
      "1300 Audio wav Files Processed\n",
      "1400 Audio wav Files Processed\n",
      "1500 Audio wav Files Processed\n",
      "1600 Audio wav Files Processed\n",
      "1700 Audio wav Files Processed\n",
      "1800 Audio wav Files Processed\n",
      "1900 Audio wav Files Processed\n",
      "2000 Audio wav Files Processed\n",
      "2100 Audio wav Files Processed\n",
      "2200 Audio wav Files Processed\n",
      "2300 Audio wav Files Processed\n",
      "2400 Audio wav Files Processed\n",
      "2500 Audio wav Files Processed\n",
      "2600 Audio wav Files Processed\n",
      "2700 Audio wav Files Processed\n",
      "2800 Audio wav Files Processed\n",
      "2900 Audio wav Files Processed\n",
      "3000 Audio wav Files Processed\n",
      "3100 Audio wav Files Processed\n",
      "3200 Audio wav Files Processed\n",
      "3300 Audio wav Files Processed\n",
      "3400 Audio wav Files Processed\n",
      "3500 Audio wav Files Processed\n",
      "3600 Audio wav Files Processed\n",
      "3700 Audio wav Files Processed\n",
      "3800 Audio wav Files Processed\n",
      "3900 Audio wav Files Processed\n",
      "4000 Audio wav Files Processed\n",
      "4100 Audio wav Files Processed\n",
      "4200 Audio wav Files Processed\n",
      "4300 Audio wav Files Processed\n",
      "4400 Audio wav Files Processed\n",
      "4500 Audio wav Files Processed\n",
      "4600 Audio wav Files Processed\n",
      "4700 Audio wav Files Processed\n",
      "4800 Audio wav Files Processed\n",
      "4900 Audio wav Files Processed\n",
      "5000 Audio wav Files Processed\n",
      "5100 Audio wav Files Processed\n",
      "5200 Audio wav Files Processed\n",
      "5300 Audio wav Files Processed\n",
      "5400 Audio wav Files Processed\n",
      "5500 Audio wav Files Processed\n",
      "5600 Audio wav Files Processed\n",
      "5700 Audio wav Files Processed\n",
      "5800 Audio wav Files Processed\n",
      "5900 Audio wav Files Processed\n",
      "6000 Audio wav Files Processed\n",
      "6100 Audio wav Files Processed\n",
      "6200 Audio wav Files Processed\n",
      "6300 Audio wav Files Processed\n",
      "6400 Audio wav Files Processed\n",
      "6500 Audio wav Files Processed\n",
      "6600 Audio wav Files Processed\n",
      "6700 Audio wav Files Processed\n",
      "6800 Audio wav Files Processed\n",
      "6900 Audio wav Files Processed\n",
      "7000 Audio wav Files Processed\n",
      "7100 Audio wav Files Processed\n",
      "7200 Audio wav Files Processed\n",
      "7300 Audio wav Files Processed\n",
      "7400 Audio wav Files Processed\n",
      "7500 Audio wav Files Processed\n",
      "7600 Audio wav Files Processed\n",
      "7700 Audio wav Files Processed\n",
      "7800 Audio wav Files Processed\n",
      "7900 Audio wav Files Processed\n",
      "8000 Audio wav Files Processed\n",
      "8100 Audio wav Files Processed\n",
      "8200 Audio wav Files Processed\n",
      "8300 Audio wav Files Processed\n",
      "8400 Audio wav Files Processed\n",
      "8500 Audio wav Files Processed\n",
      "8600 Audio wav Files Processed\n",
      "8700 Audio wav Files Processed\n",
      "8800 Audio wav Files Processed\n",
      "8900 Audio wav Files Processed\n",
      "9000 Audio wav Files Processed\n",
      "9100 Audio wav Files Processed\n",
      "9200 Audio wav Files Processed\n",
      "9300 Audio wav Files Processed\n",
      "9400 Audio wav Files Processed\n",
      "9500 Audio wav Files Processed\n",
      "9600 Audio wav Files Processed\n",
      "9700 Audio wav Files Processed\n",
      "9800 Audio wav Files Processed\n",
      "9900 Audio wav Files Processed\n",
      "10000 Audio wav Files Processed\n",
      "10100 Audio wav Files Processed\n",
      "10200 Audio wav Files Processed\n",
      "10300 Audio wav Files Processed\n",
      "10400 Audio wav Files Processed\n",
      "10500 Audio wav Files Processed\n",
      "10600 Audio wav Files Processed\n",
      "10700 Audio wav Files Processed\n",
      "10800 Audio wav Files Processed\n",
      "10900 Audio wav Files Processed\n",
      "11000 Audio wav Files Processed\n",
      "11100 Audio wav Files Processed\n",
      "11200 Audio wav Files Processed\n",
      "11300 Audio wav Files Processed\n",
      "11400 Audio wav Files Processed\n",
      "11500 Audio wav Files Processed\n",
      "11600 Audio wav Files Processed\n",
      "11700 Audio wav Files Processed\n",
      "11800 Audio wav Files Processed\n",
      "11900 Audio wav Files Processed\n",
      "12000 Audio wav Files Processed\n",
      "12100 Audio wav Files Processed\n",
      "12200 Audio wav Files Processed\n",
      "12300 Audio wav Files Processed\n",
      "12400 Audio wav Files Processed\n",
      "12500 Audio wav Files Processed\n",
      "12600 Audio wav Files Processed\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('music.hdf5', 'a') as f:\n",
    "    for i, wav in enumerate(audio):\n",
    "        y, _ = librosa.load(path + wav)\n",
    "        dset = f.create_dataset(str(i), data=y)\n",
    "        if i % 100 == 0:\n",
    "            print(\"{} Audio wav Files Processed\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12678\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('music.hdf5', 'r') as f:\n",
    "    l = len(f.keys())\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(batch_size, seq_len):\n",
    "    x = np.ndarray(shape=(batch_size, seq_len))\n",
    "    y = np.ndarray(shape=(batch_size, seq_len))\n",
    "    \n",
    "    l = 12678\n",
    "    \n",
    "    with h5py.File('music.hdf5', 'r') as f:\n",
    "        for i in range(0,l,batch_size):\n",
    "            cnt = 0\n",
    "            for j in range(i,i+batch_size):\n",
    "                x[cnt] = f[str(j)][:seq_len]\n",
    "                y[cnt] = f[str(j)][1:seq_len + 1]\n",
    "                cnt += 1\n",
    "            yield (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itr = next_batch(32,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = next(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from GenreFeatureData import GenreFeatureData  # local python class with Audio feature extraction (librosa)\n",
    "\n",
    "# Turn off TF verbose logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "\n",
    "genre_features = GenreFeatureData()\n",
    "genre_features.load_preprocess_data()\n",
    "# genre_features.load_deserialize_data()\n",
    "\n",
    "# Keras optimizer defaults:\n",
    "# Adam   : lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.\n",
    "# RMSprop: lr=0.001, rho=0.9, epsilon=1e-8, decay=0.\n",
    "# SGD    : lr=0.01, momentum=0., decay=0.\n",
    "opt = Adam()\n",
    "\n",
    "batch_size = 35\n",
    "nb_epochs = 400\n",
    "\n",
    "print(\"Training X shape: \" + str(genre_features.train_X.shape))\n",
    "print(\"Training Y shape: \" + str(genre_features.train_Y.shape))\n",
    "print(\"Dev X shape: \" + str(genre_features.dev_X.shape))\n",
    "print(\"Dev Y shape: \" + str(genre_features.dev_Y.shape))\n",
    "print(\"Test X shape: \" + str(genre_features.test_X.shape))\n",
    "print(\"Test Y shape: \" + str(genre_features.test_X.shape))\n",
    "\n",
    "input_shape = (genre_features.train_X.shape[1], genre_features.train_X.shape[2])\n",
    "print('Build LSTM RNN model ...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, dropout=0.05, recurrent_dropout=0.35, return_sequences=True, input_shape=input_shape))\n",
    "model.add(LSTM(units=32, dropout=0.05, recurrent_dropout=0.35, return_sequences=False))\n",
    "model.add(Dense(units=genre_features.train_Y.shape[1], activation='softmax'))\n",
    "\n",
    "print(\"Compiling ...\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "print(\"Training ...\")\n",
    "model.fit(genre_features.train_X, genre_features.train_Y, batch_size=batch_size, epochs=nb_epochs)\n",
    "\n",
    "print(\"\\nValidating ...\")\n",
    "score, accuracy = model.evaluate(genre_features.dev_X, genre_features.dev_Y, batch_size=batch_size, verbose=1)\n",
    "print(\"Dev loss:  \", score)\n",
    "print(\"Dev accuracy:  \", accuracy)\n",
    "\n",
    "\n",
    "print(\"\\nTesting ...\")\n",
    "score, accuracy = model.evaluate(genre_features.test_X, genre_features.test_Y, batch_size=batch_size, verbose=1)\n",
    "print(\"Test loss:  \", score)\n",
    "print(\"Test accuracy:  \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = io.open(path, encoding='utf-8').read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
