{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets as dsets\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "style.use('ggplot')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import librosa \n",
    "import librosa.display\n",
    "import h5py \n",
    "\n",
    "import os, sys, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "arg = {\n",
    "    'lr' : 0.001,\n",
    "    'epochs': 25,\n",
    "    'img_size': (1, 20, 172) ,\n",
    "    'image_size': (1*20*172),\n",
    "    'img_height': 20,\n",
    "    'img_width': 172,\n",
    "    'input_channel': 1,\n",
    "    'keep_prob': 0.2,\n",
    "    'batch_size': 86\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BUFFER_LENGTH = 1024\n",
    "HOP_LENGTH = 512\n",
    "MEL_COUNT = 20\n",
    "\n",
    "def GenerateSpectogram(y):\n",
    "    stft = librosa.stft(y, n_fft=BUFFER_LENGTH, hop_length=HOP_LENGTH)\n",
    "    D = np.abs(stft) ** 2\n",
    "    S = librosa.feature.melspectrogram(S=D, n_mels=MEL_COUNT)\n",
    "    mi = np.min(S[np.nonzero(S)])\n",
    "    S[S == 0] = mi    \n",
    "    S = np.log(S)\n",
    "    return S.reshape(1, 20, 173)[:,:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size):\n",
    "    x = np.ndarray(shape=(batch_size, *arg['img_size']))    \n",
    "    l = 12678\n",
    "    while 1:\n",
    "        with h5py.File('music.hdf5', 'r') as f:\n",
    "            for i in range(0,l,batch_size):\n",
    "                cnt = 0\n",
    "                j = i\n",
    "                while j < i + batch_size:\n",
    "                    tmp = GenerateSpectogram(f[str(j)][:])\n",
    "                    if np.isnan(tmp).any():\n",
    "                        continue\n",
    "                    else:\n",
    "                        x[cnt] = tmp\n",
    "                    j += 1\n",
    "                    cnt += 1\n",
    "                yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PlotMelSpec(mel_spec, title):\n",
    "    librosa.display.specshow(mel_spec)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel spectrogram (%s)' % title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 172)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with h5py.File('music.hdf5', 'r') as f:\n",
    "    x = GenerateSpectogram(f['1'][:])\n",
    "x.shape\n",
    "\n",
    "# PlotMelSpec(x[0,:,:],'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Model\n",
    "# class Autoencoder(nn.Module):\n",
    "\n",
    "#     def __init__(self, arg):\n",
    "#         super(Autoencoder, self).__init__()\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(arg['input_channel'], 32, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(p=arg['keep_prob']),\n",
    "\n",
    "#             nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(p=arg['keep_prob']),\n",
    "            \n",
    "#             nn.MaxPool2d(2),\n",
    "\n",
    "#             nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(p=arg['keep_prob']),\n",
    "\n",
    "#             nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(p=arg['keep_prob']),\n",
    "\n",
    "#             nn.MaxPool2d(2)\n",
    "#             )\n",
    "\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "\n",
    "#             nn.ConvTranspose2d(64, 64, kernel_size=5, padding=2),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(p=arg['keep_prob']),\n",
    "\n",
    "#             nn.ConvTranspose2d(64, 32, kernel_size=5, padding=2, stride=2, output_padding=1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(p=arg['keep_prob']),\n",
    "\n",
    "#             nn.ConvTranspose2d(32, 32, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(p=arg['keep_prob']),\n",
    "\n",
    "#             nn.ConvTranspose2d(32, arg['input_channel'], kernel_size=3, padding=1, stride=2, output_padding=1),\n",
    "#             nn.Dropout2d(p=arg['keep_prob']),\n",
    "#             nn.Sigmoid()          \t\n",
    "#         )\n",
    "\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         h = self.encoder(x)\n",
    "#         out = self.decoder(h)\n",
    "\n",
    "#         return out, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, arg, h_dim, z_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(arg['image_size'], h_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(h_dim, z_dim*2))  # 2 for mean and variance.\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, arg['image_size']),\n",
    "            nn.Sigmoid())\n",
    "    \n",
    "    def reparametrize(self, mu, log_var):\n",
    "        \"\"\"\"z = mean + eps * sigma where eps is sampled from N(0, 1).\"\"\"\n",
    "        eps = to_var(torch.randn(mu.size(0), mu.size(1)))\n",
    "        z = mu + eps * torch.exp(log_var/2)    # 2 for convert var to std\n",
    "        return z\n",
    "                     \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, log_var = torch.chunk(h, 2, dim=1)  # mean and log variance.\n",
    "        z = self.reparametrize(mu, log_var)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, log_var\n",
    "    \n",
    "    def sample(self, z):\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "ae = Autoencoder(arg, 512, 128)\n",
    "if torch.cuda.is_available():\n",
    "    ae.cuda()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(ae.parameters(), lr=arg['lr'])\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = 12678 // arg['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Step [1/147], Loss: 1.4572999957188444e+18\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `x >= 0. && x <= 1.' failed. input value should be between 0~1, but got nan at /pytorch/torch/lib/THNN/generic/BCECriterion.c:34",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e4ec2e1dbaba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Reconstruction Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mrecon_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mkl_divergence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_var\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shashwat/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shashwat/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         return F.binary_cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 297\u001b[0;31m                                       size_average=self.size_average)\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shashwat/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shashwat/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, target, *args)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         getattr(ctx._backend, update_output.name)(ctx._backend.library_state, input, target,\n\u001b[0;32m---> 47\u001b[0;31m                                                   output, *ctx.additional_args)\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `x >= 0. && x <= 1.' failed. input value should be between 0~1, but got nan at /pytorch/torch/lib/THNN/generic/BCECriterion.c:34"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "for epoch in range(arg['epochs']):\n",
    "    for i, spectograms in enumerate(next_batch(arg['batch_size'])):\n",
    "\n",
    "        spectograms = spectograms.reshape(-1, arg['image_size'])\n",
    "        targets = np.copy(spectograms)\n",
    "        \n",
    "        if np.isnan(targets).any():\n",
    "            print('Yes: ' + str(i))\n",
    "        \n",
    "        spectograms = to_var(torch.from_numpy(spectograms.astype('float32')))\n",
    "        targets = to_var(torch.from_numpy(targets.astype('float32')))\n",
    "        \n",
    "        \n",
    "        # Forward\n",
    "        out, mu, log_var = ae(spectograms)\n",
    "        \n",
    "        # Reconstruction Loss\n",
    "        recon_loss = criterion(out, targets)\n",
    "        kl_divergence = torch.sum(0.5 * (mu**2 + torch.exp(log_var) - log_var -1))\n",
    "    \n",
    "        loss = recon_loss + kl_divergence\n",
    "        \n",
    "        # Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        if i%100 == 0:\n",
    "            print(\"Epoch [{}/{}], Step [{}/{}], Loss: {}\".format(\n",
    "                epoch+1,arg['epochs'],i+1, steps, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the Trained Model\n",
    "torch.save(ae.state_dict(), 'ae.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "ae.eval()\n",
    "\n",
    "idx = random.randint(0, 12678)\n",
    "\n",
    "with h5py.File('music.hdf5', 'r') as f:\n",
    "    fixed_x = GenerateSpectogram(f[str(idx)][:])\n",
    "\n",
    "fixed_x = fixed_x.reshape(1, arg['image_size']\n",
    "fixed_x = to_var(torch.from_numpy(fixed_x).astype('float32')))\n",
    "\n",
    "out, latent = ae(fixed_x)\n",
    "\n",
    "# TODO\n",
    "# torchvision.utils.save_image(out.data.cpu(), 'Reconstructed_Image.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
